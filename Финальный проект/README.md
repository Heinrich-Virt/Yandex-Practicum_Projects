## Задача проекта

Обработать данные, исследовать данные, создать модель предсказывающею уйдет клиент в ближайшее время или нет. 

## Описание задачи

Оператор связи «Ниединогоразрыва.ком» хочет научиться прогнозировать отток клиентов. Если выяснится, что пользователь планирует уйти, ему будут предложены промокоды и специальные условия. Команда оператора собрала персональные данные о некоторых клиентах, информацию об их тарифах и договорах.

## Заключение

При выполнении можно выделить следующие шаги:

- Загрузка данных.
- Предобработка данных.
- Создание дополнительных признаков и исследовательский анализ данных. В данном пункте мы объединили таблицы. И заполнили пропуски в получившемся датафрейме. Так же, были созданы дополнительные признаки с помощью столбцов "EndData" и "BeginData". Из "EndData" вычли "BeginData". Получили количесвто дней пользования услугами. Если клиенет еще пользуется, то из 2020-02-01 отнимаем "BeginData". Получили наш целевой признак. Далее рассмотрены графически отличия клиентов, которые ушли и которые остались. В выводе мы описали данные закономерности.
- Обучение нескольких моделей и подбор гиперпараметров. Но сначало были удалены следующие столбцы: "BeginData", "EndData" и "customerID". Данные признаки нам не нужны и не несут в себе уже никакого смысла для предсказания. После этого мы подбирали гиперпараметры для Случайного леса, CatBoost и LightGBM.
- Проверка лучшей модели на тестовой выборке. Были проверены метрики на CatBoost. Именно эта модель и дала наилучший орезультат.

Это отличается от нашего первоначального плана.

Не было сделано:

- Удаление коллинеарных признаков. Данный пункт не понадобился, так как метрика у нашей модели и без этого является хорошей.
- Удаление дисбаланса классов. Так же, даная метрика не понадобилась за счет того, что для нашей модели это оказалось не проблема и метрика вышла высокая.

Было слелано то, что не планировали изначально:
- Создание дополнительных признаков. Данный пункт был необходим, так как это целевой признак. При ознакомлении с данными я еще не увидел, что нам придется самим делать целевой признак.

Лучшей моделью оказалась CatBoost с метриками:
- learning_rate = 0.2
- max_depth = 2

Полученные значения на модели:
- roc auc на тестовой выборке = 0.9384
- accuracy = 0.8983
